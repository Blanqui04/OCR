# src/ui/app.py (actualitzat amb IA)
import streamlit as st
import json
import pandas as pd
import os
import tempfile
import sys
import traceback
from pathlib import Path
from io import BytesIO
from datetime import datetime

# Afegir el directori src al path per importar els m√≤duls
sys.path.append(str(Path(__file__).parent.parent))

try:
    from pipeline import OCRPipeline
    
    # Intentar importar components d'IA
    try:
        from ai_enhanced_pipeline import AIEnhancedPipeline, DEFAULT_AI_CONFIG
        AI_ENHANCED_AVAILABLE = True
    except ImportError:
        AI_ENHANCED_AVAILABLE = False
        
except ImportError as e:
    st.error(f"Error important OCRPipeline: {e}")
    # Fallback a importacions individuals
    try:
        from pdf_to_images import pdf_to_images
        from ocr_processor import ocr_with_boxes
        from data_extractor import extract_technical_data
        from dimension_linker import detect_lines, link_text_to_lines
        OCRPipeline = None
        AI_ENHANCED_AVAILABLE = False
    except ImportError as e2:
        st.error(f"Error important m√≤duls individuals: {e2}")
        OCRPipeline = None
        AI_ENHANCED_AVAILABLE = False

st.set_page_config(page_title="Validador de Pl√†nols T√®cnics amb IA", layout="wide")

# Configurar l'estat de la sessi√≥ per IA
if 'ai_enabled' not in st.session_state:
    st.session_state.ai_enabled = AI_ENHANCED_AVAILABLE
if 'ai_pipeline' not in st.session_state:
    st.session_state.ai_pipeline = None
if 'processing_results' not in st.session_state:
    st.session_state.processing_results = None

st.title("ü§ñüìê Validador de Pl√†nols T√®cnics amb IA")

# Sidebar per configuraci√≥ d'IA
with st.sidebar:
    st.header("‚öôÔ∏è Configuraci√≥")
    
    # Configuraci√≥ d'IA
    st.subheader("ü§ñ Intel¬∑lig√®ncia Artificial")
    
    if AI_ENHANCED_AVAILABLE:
        st.success("‚úÖ Components d'IA disponibles")
        
        # Toggle per activar/desactivar IA
        ai_enabled = st.checkbox(
            "Utilitzar IA h√≠brida", 
            value=st.session_state.ai_enabled,
            help="Combina detecci√≥ amb IA i regles tradicionals per m√†xima precisi√≥"
        )
        st.session_state.ai_enabled = ai_enabled
        
        if ai_enabled:
            # Inicialitzar pipeline d'IA si cal
            if st.session_state.ai_pipeline is None:
                with st.spinner("Inicialitzant pipeline d'IA..."):
                    try:
                        # Crear configuraci√≥ d'IA si no existeix
                        project_root = Path(__file__).parent.parent.parent
                        config_path = project_root / "config_ai.json"
                        
                        if not config_path.exists():
                            with open(config_path, 'w') as f:
                                json.dump(DEFAULT_AI_CONFIG, f, indent=2)
                        
                        st.session_state.ai_pipeline = AIEnhancedPipeline(str(config_path))
                        st.success("Pipeline d'IA inicialitzat!")
                    except Exception as e:
                        st.error(f"Error inicialitzant IA: {e}")
                        st.session_state.ai_enabled = False
            
            if st.session_state.ai_pipeline:
                # Mostrar estad√≠stiques del model
                stats = st.session_state.ai_pipeline.get_model_performance_stats()
                
                col1, col2 = st.columns(2)
                with col1:
                    if stats['model_loaded']:
                        st.success("üéØ Model carregat")
                    else:
                        st.warning("‚ö†Ô∏è Model no carregat")
                
                with col2:
                    st.metric("Precisi√≥ estimada", f"{stats['accuracy_estimate']:.1%}")
                
                st.metric("Correccions d'usuari", stats['total_corrections'])
                
                # Configuraci√≥ avan√ßada
                with st.expander("Configuraci√≥ avan√ßada"):
                    confidence_threshold = st.slider(
                        "Llindar de confian√ßa", 
                        0.1, 1.0, 0.7, 0.05,
                        help="Elements amb confian√ßa inferior necessitaran revisi√≥ humana"
                    )
        
    else:
        st.error("‚ùå Components d'IA no disponibles")
        st.info("üí° Instal¬∑la les depend√®ncies d'IA per habilitar aquesta funcionalitat")
        st.session_state.ai_enabled = False

# Pestanyes principals amb IA
tab1, tab2, tab3, tab4 = st.tabs(["üì§ Pujar Fitxer", "üîç Resultats", "üîß Validaci√≥ HIITL", "üìä Export de Dades"])

with tab1:
    st.header("Pujar fitxer PDF")
    
    # Selector del m√®tode de processament
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_file = st.file_uploader(
            "Escull un fitxer PDF", 
            type=['pdf'],
            help="Puja un pl√†nol t√®cnic en format PDF per analitzar"
        )
    
    with col2:
        processing_method = st.selectbox(
            "M√®tode de processament",
            ["IA H√≠brida", "Nom√©s Regles", "Nom√©s IA"] if st.session_state.ai_enabled else ["Nom√©s Regles"],
            help="Escull com processar el document"
        )
    
    if uploaded_file is not None:
        # Guardar fitxer temporalment
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        col1, col2, col3 = st.columns(3)
        
        with col2:
            if st.button("üöÄ Processar amb IA" if st.session_state.ai_enabled else "üöÄ Processar", 
                        type="primary", use_container_width=True):
                
                with st.spinner("Processant document..."):
                    try:
                        if st.session_state.ai_enabled and st.session_state.ai_pipeline:
                            # Processament amb IA
                            use_ai = processing_method in ["IA H√≠brida", "Nom√©s IA"]
                            results = st.session_state.ai_pipeline.process_document_with_ai(tmp_path, use_ai)
                            st.session_state.processing_results = results
                            
                            if results['status'] == 'success':
                                st.success(f"‚úÖ Document processat amb √®xit!")
                                st.info(f"üìÑ {len(results['pages'])} p√†gines processades")
                                st.info(f"üîç {results['total_elements']} elements detectats")
                                
                                if results['human_review_required']:
                                    st.warning("‚ö†Ô∏è Alguns elements necessiten revisi√≥ humana")
                            else:
                                st.error(f"‚ùå Error: {results.get('error', 'Unknown error')}")
                        
                        else:
                            # Processament tradicional
                            st.info("Utilitzant processament tradicional...")
                            # Aqu√≠ aniria la l√≤gica existent del pipeline tradicional
                            st.warning("Implementar fallback al pipeline tradicional")
                    
                    except Exception as e:
                        st.error(f"Error processant: {str(e)}")
                        st.error(traceback.format_exc())
                
                # Netejar fitxer temporal
                try:
                    os.unlink(tmp_path)
                except:
                    pass

with tab2:
    st.header("üîç Resultats de la Detecci√≥")
    
    if st.session_state.processing_results:
        results = st.session_state.processing_results
        
        # Resum general
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üìÑ P√†gines", len(results.get('pages', [])))
        
        with col2:
            st.metric("üîç Elements totals", results.get('total_elements', 0))
        
        with col3:
            needs_review = sum(len(page.get('human_review_tasks', [])) for page in results.get('pages', []))
            st.metric("‚ö†Ô∏è Necessiten revisi√≥", needs_review)
        
        with col4:
            ai_enabled_display = "‚úÖ S√≠" if results.get('ai_enabled', False) else "‚ùå No"
            st.metric("ü§ñ IA utilitzada", ai_enabled_display)
        
        # Resultats per p√†gina
        st.subheader("Resultats per p√†gina")
        
        for page in results.get('pages', []):
            with st.expander(f"üìÑ P√†gina {page['page_number']} - {len(page.get('elements', []))} elements"):
                
                # Informaci√≥ de la p√†gina
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**M√®tode de processament:**", page.get('processing_method', 'Unknown'))
                    if 'ai_metadata' in page:
                        st.write("**Ratio alta confian√ßa:**", f"{page['ai_metadata'].get('high_confidence_ratio', 0):.1%}")
                
                with col2:
                    st.write("**Necessita revisi√≥:**", "S√≠" if page.get('needs_human_review', False) else "No")
                    st.write("**Elements detectats:**", len(page.get('elements', [])))
                
                # Taula d'elements
                if page.get('elements'):
                    elements_df = pd.DataFrame([
                        {
                            'Tipus': elem.get('type', ''),
                            'Confian√ßa': f"{elem.get('confidence', 0):.2f}",
                            'Font': elem.get('source', ''),
                            'Text': elem.get('text', '')[:50] + '...' if len(elem.get('text', '')) > 50 else elem.get('text', '')
                        }
                        for elem in page['elements']
                    ])
                    st.dataframe(elements_df, use_container_width=True)
                
                # Relacions espacials
                if page.get('relationships'):
                    st.write("**Relacions espacials trobades:**")
                    for rel in page['relationships'][:5]:  # Mostrar nom√©s les primeres 5
                        st.write(f"- {rel.get('type', 'Unknown relation')}")
    
    else:
        st.info("üëÜ Puja i processa un document per veure els resultats aqu√≠")

with tab3:
    st.header("üîß Validaci√≥ Human-in-the-Loop (HIITL)")
    
    if st.session_state.processing_results and st.session_state.processing_results.get('human_review_required'):
        st.warning("‚ö†Ô∏è Hi ha elements que necessiten la teva revisi√≥ per millorar la precisi√≥ del model")
        
        # Recopilar totes les tasques de revisi√≥
        all_review_tasks = []
        for page in st.session_state.processing_results.get('pages', []):
            for task in page.get('human_review_tasks', []):
                task['page_number'] = page['page_number']
                all_review_tasks.append(task)
        
        if all_review_tasks:
            st.write(f"**Total tasques de revisi√≥:** {len(all_review_tasks)}")
            
            # Selector de tasca
            task_index = st.selectbox(
                "Selecciona tasca a revisar:",
                range(len(all_review_tasks)),
                format_func=lambda x: f"P√†gina {all_review_tasks[x]['page_number']} - {all_review_tasks[x].get('suggested_type', 'Unknown')}"
            )
            
            if task_index is not None:
                current_task = all_review_tasks[task_index]
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.write("**Pregunta de revisi√≥:**")
                    st.info(current_task.get('review_question', 'No question available'))
                    
                    st.write("**Detalls de l'element:**")
                    st.json({
                        'Tipus suggerit': current_task.get('suggested_type', ''),
                        'Confian√ßa': current_task.get('confidence', 0),
                        'Coordenades': current_task.get('bbox', {})
                    })
                
                with col2:
                    st.write("**Correcci√≥:**")
                    
                    # Tipus disponibles per correcci√≥
                    available_types = [
                        "dimension_text", "arrow", "tolerance", "symbol", 
                        "info_text", "title", "line", "table", "scale", 
                        "north_arrow", "border", "legend", "other"
                    ]
                    
                    corrected_type = st.selectbox(
                        "Tipus correcte:",
                        available_types,
                        index=available_types.index(current_task.get('suggested_type', 'other')) 
                        if current_task.get('suggested_type', 'other') in available_types else 0
                    )
                    
                    if st.button("‚úÖ Confirmar correcci√≥", type="primary"):
                        # Guardar feedback
                        if st.session_state.ai_pipeline and st.session_state.ai_pipeline.learning_manager:
                            try:
                                st.session_state.ai_pipeline.learning_manager.save_user_correction(
                                    current_task.get('element', {}), 
                                    corrected_type, 
                                    "streamlit_user"
                                )
                                st.success("‚úÖ Correcci√≥ guardada! El model millorar√† amb aquesta informaci√≥.")
                                
                                # Actualitzar estad√≠stiques
                                st.rerun()
                                
                            except Exception as e:
                                st.error(f"Error guardant correcci√≥: {e}")
                        else:
                            st.warning("Sistema d'aprenentatge no disponible")
        
    elif st.session_state.processing_results:
        st.success("üéâ Tots els elements han estat detectats amb alta confian√ßa! No cal revisi√≥ manual.")
    
    else:
        st.info("üëÜ Processa primer un document per veure tasques de validaci√≥ aqu√≠")

with tab4:
    st.header("üìä Export de Dades")
    
    if st.session_state.processing_results:
        results = st.session_state.processing_results
        
        st.subheader("Formats d'exportaci√≥ disponibles")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üìä Exportar a Excel", type="primary"):
                with st.spinner("Creant fitxer Excel..."):
                    try:
                        if st.session_state.ai_pipeline:
                            export_path = st.session_state.ai_pipeline.export_results_enhanced(results, "excel")
                            st.success(f"‚úÖ Excel creat: {Path(export_path).name}")
                            
                            # Oferir desc√†rrega
                            with open(export_path, 'rb') as f:
                                st.download_button(
                                    "‚¨áÔ∏è Descarregar Excel",
                                    f.read(),
                                    f"resultats_ia_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                        else:
                            st.error("Pipeline d'IA no disponible per exportaci√≥")
                    except Exception as e:
                        st.error(f"Error creant Excel: {e}")
        
        with col2:
            if st.button("üìÑ Exportar JSON Schema", type="secondary"):
                with st.spinner("Creant JSON Schema..."):
                    try:
                        if st.session_state.ai_pipeline:
                            export_path = st.session_state.ai_pipeline.export_results_enhanced(results, "json_schema")
                            st.success(f"‚úÖ JSON Schema creat: {Path(export_path).name}")
                            
                            # Oferir desc√†rrega
                            with open(export_path, 'r', encoding='utf-8') as f:
                                st.download_button(
                                    "‚¨áÔ∏è Descarregar JSON Schema",
                                    f.read(),
                                    f"resultats_schema_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                                    "application/json"
                                )
                        else:
                            st.error("Pipeline d'IA no disponible per exportaci√≥")
                    except Exception as e:
                        st.error(f"Error creant JSON Schema: {e}")
        
        with col3:
            if st.button("üóÇÔ∏è Exportar JSON Simple", type="secondary"):
                with st.spinner("Creant JSON..."):
                    try:
                        if st.session_state.ai_pipeline:
                            export_path = st.session_state.ai_pipeline.export_results_enhanced(results, "json")
                            st.success(f"‚úÖ JSON creat: {Path(export_path).name}")
                            
                            # Oferir desc√†rrega
                            with open(export_path, 'r', encoding='utf-8') as f:
                                st.download_button(
                                    "‚¨áÔ∏è Descarregar JSON",
                                    f.read(),
                                    f"resultats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                                    "application/json"
                                )
                        else:
                            st.error("Pipeline d'IA no disponible per exportaci√≥")
                    except Exception as e:
                        st.error(f"Error creant JSON: {e}")
        
        # Previsualitzaci√≥ de dades
        st.subheader("Previsualitzaci√≥ de dades")
        
        # Crear dataframe resum per mostrar
        all_elements = []
        for page in results.get('pages', []):
            for elem in page.get('elements', []):
                elem_data = {
                    'P√†gina': page['page_number'],
                    'Tipus': elem.get('type', ''),
                    'Confian√ßa': elem.get('confidence', 0),
                    'Font': elem.get('source', ''),
                    'Text': elem.get('text', '')[:100] + '...' if len(elem.get('text', '')) > 100 else elem.get('text', '')
                }
                all_elements.append(elem_data)
        
        if all_elements:
            df_preview = pd.DataFrame(all_elements)
            st.dataframe(df_preview, use_container_width=True)
            
            # Estad√≠stiques r√†pides
            st.subheader("Estad√≠stiques")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                type_counts = df_preview['Tipus'].value_counts()
                st.write("**Elements per tipus:**")
                st.write(type_counts)
            
            with col2:
                avg_confidence = df_preview['Confian√ßa'].mean()
                st.metric("Confian√ßa mitjana", f"{avg_confidence:.2f}")
            
            with col3:
                source_counts = df_preview['Font'].value_counts()
                st.write("**Elements per font:**")
                st.write(source_counts)
    
    else:
        st.info("üëÜ Processa primer un document per exportar les dades")

# Funcions d'exportaci√≥
def create_excel_export(data):
    """Crea un fitxer Excel amb les dades processades"""
    output = BytesIO()
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # Full 1: Informaci√≥ de la pe√ßa
        part_info_df = pd.DataFrame([data.get("part_info", {})])
        part_info_df.to_excel(writer, sheet_name='Informaci√≥_Pe√ßa', index=False)
        
        # Full 2: Cotes
        if data.get("dimensions"):
            dimensions_df = pd.DataFrame(data["dimensions"])
            dimensions_df.to_excel(writer, sheet_name='Cotes', index=False)
        
        # Full 3: Toler√†ncies Geom√®triques
        if data.get("geometric_tolerances"):
            tolerances_df = pd.DataFrame(data["geometric_tolerances"])
            tolerances_df.to_excel(writer, sheet_name='Toler√†ncies', index=False)
        
        # Full 4: Taules Extretes
        if data.get("raw_tables"):
            for i, table in enumerate(data["raw_tables"]):
                table_data = table.get("data", [])
                if table_data:
                    try:
                        table_df = pd.DataFrame(table_data)
                        sheet_name = f'Taula_{i+1}'
                        table_df.to_excel(writer, sheet_name=sheet_name, index=False)
                    except:
                        # Si no es pot convertir a DataFrame, crear un full amb info
                        info_df = pd.DataFrame([{
                            'Taula': i+1,
                            'Tipus': table.get('name', 'Desconeguda'),
                            'Dades': str(table_data)[:1000]  # Limitar text
                        }])
                        info_df.to_excel(writer, sheet_name=f'Taula_{i+1}_Info', index=False)
    
    output.seek(0)
    return output.getvalue()

def create_json_schema_export(data):
    """Crea un JSON amb esquema validat"""
    export_schema = {
        "$schema": "http://json-schema.org/draft-07/schema#",
        "title": "Validaci√≥ de Pl√†nols T√®cnics",
        "type": "object",
        "properties": {
            "metadata": {
                "type": "object",
                "properties": {
                    "export_timestamp": {"type": "string"},
                    "validation_completed": {"type": "boolean"},
                    "total_elements": {"type": "integer"}
                }
            },
            "part_info": {"type": "object"},
            "dimensions": {"type": "array"},
            "geometric_tolerances": {"type": "array"},
            "raw_tables": {"type": "array"}
        },
        "required": ["metadata", "part_info"]
    }
    
    # Crear dades amb esquema
    schema_data = {
        "schema": export_schema,
        "data": {
            "metadata": {
                "export_timestamp": str(pd.Timestamp.now().isoformat()),
                "validation_completed": True,
                "total_elements": (len(data.get("dimensions", [])) + 
                                 len(data.get("geometric_tolerances", [])) + 
                                 len(data.get("raw_tables", [])))
            },
            "part_info": data.get("part_info", {}),
            "dimensions": data.get("dimensions", []),
            "geometric_tolerances": data.get("geometric_tolerances", []),
            "raw_tables": data.get("raw_tables", [])
        }
    }
    
    return json.dumps(schema_data, indent=2, ensure_ascii=False)

# Carregar dades integrades
@st.cache_data
def load_integrated_data():
    """Carrega les dades del fitxer final_output.json"""
    try:
        base_dir = str(Path(__file__).parent.parent.parent)
        data_path = os.path.join(base_dir, "data", "final_output.json")
        
        if os.path.exists(data_path):
            with open(data_path, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            return None
    except Exception as e:
        st.error(f"Error carregant les dades: {e}")
        return None

# Intentar carregar dades existents
data = load_integrated_data()

if data is None:
    st.warning("‚ö†Ô∏è No s'han trobat dades processades.")
    st.info("üí° Pots:")
    st.write("1. Executar `main.py` primer per processar un PDF")
    st.write("2. O carregar un nou PDF aqu√≠:")
    
    # Opci√≥ per carregar i processar un nou PDF
    uploaded_file = st.file_uploader("Selecciona un PDF", type=['pdf'])
    
    if uploaded_file is not None:
        if st.button("üöÄ Processar PDF", type="primary"):
            if OCRPipeline is None:
                st.error("‚ùå OCRPipeline no est√† disponible. Revisa les importacions.")
                st.stop()
                
            with st.spinner("Processant el PDF..."):
                # Guardar el fitxer carregat temporalment
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_path = tmp_file.name
                
                try:
                    # Utilitzar el pipeline integrat
                    base_dir = str(Path(__file__).parent.parent.parent)
                    
                    # Crear pipeline
                    pipeline = OCRPipeline(base_dir)
                    
                    # Processar PDF
                    st.info("‚öôÔ∏è Executant pipeline complet...")
                    results = pipeline.process_pdf(tmp_path, save_files=True)
                    
                    st.success("‚úÖ Processament completat!")
                    st.info("üîÑ Recarrega la p√†gina per veure els resultats.")
                    
                except Exception as e:
                    st.error(f"‚ùå Error durant el processament: {str(e)}")
                    st.exception(e)
                finally:
                    # Netejar fitxer temporal
                    if os.path.exists(tmp_path):
                        os.unlink(tmp_path)
    
    st.stop()

# Informaci√≥ general
st.sidebar.header("üìÑ Informaci√≥ de la Pe√ßa")
part = data.get("part_info", {})
st.sidebar.write(f"**N√∫mero:** {part.get('part_number', 'N/A')}")
st.sidebar.write(f"**Material:** {part.get('material', 'N/A')}")
st.sidebar.write(f"**Revisi√≥:** {part.get('revision', 'N/A')}")

# Estad√≠stiques r√†pides
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("üìè Cotes", len(data.get("dimensions", [])))
with col2:
    st.metric("‚öôÔ∏è Toler√†ncies", len(data.get("geometric_tolerances", [])))
with col3:
    st.metric("üìä Taules", len(data.get("raw_tables", [])))
with col4:
    total_elements = (len(data.get("dimensions", [])) + 
                     len(data.get("geometric_tolerances", [])) + 
                     len(data.get("raw_tables", [])))
    st.metric("üîç Total Elements", total_elements)

# Pestanyes
tab1, tab2, tab3 = st.tabs(["üìè Cotes", "‚öôÔ∏è Toler√†ncies Geom√®triques", "üìä Taules"])

with tab1:
    st.subheader("üìè Cotes Detectades")
    
    if data.get("dimensions"):
        for i, dim in enumerate(data["dimensions"]):
            col1, col2, col3 = st.columns([4, 1, 1])
            with col1:
                desc = dim.get("description", dim.get("text", "Sense descripci√≥"))
                confidence = dim.get("confidence", "N/A")
                if isinstance(confidence, (int, float)):
                    st.text(f"‚Ä¢ {desc} (confian√ßa: {confidence:.1f})")
                else:
                    st.text(f"‚Ä¢ {desc}")
            with col2:
                is_correct = st.checkbox("Correcte?", True, key=f"dim_{i}")
            with col3:
                if st.button("üìù", key=f"edit_dim_{i}", help="Editar"):
                    st.session_state[f'editing_dim_{i}'] = True
            
            # Edici√≥ inline
            if st.session_state.get(f'editing_dim_{i}', False):
                new_desc = st.text_input(f"Corregir descripci√≥ {i+1}:", value=desc, key=f"new_desc_{i}")
                col_save, col_cancel = st.columns(2)
                with col_save:
                    if st.button("üíæ Guardar", key=f"save_dim_{i}"):
                        data["dimensions"][i]['description'] = new_desc
                        st.session_state[f'editing_dim_{i}'] = False
                        st.rerun()
                with col_cancel:
                    if st.button("‚ùå Cancel¬∑lar", key=f"cancel_dim_{i}"):
                        st.session_state[f'editing_dim_{i}'] = False
                        st.rerun()
    else:
        st.info("No s'han detectat cotes en aquest document.")

with tab2:
    st.subheader("‚öôÔ∏è Toler√†ncies Geom√®triques")
    
    if data.get("geometric_tolerances"):
        for i, tol in enumerate(data["geometric_tolerances"]):
            col1, col2 = st.columns([4, 1])
            with col1:
                symbol = tol.get('symbol', 'N/A')
                value = tol.get('value', 'N/A')
                datum = tol.get('datum', '')
                tol_type = tol.get('type', 'N/A')
                
                if datum:
                    st.text(f"{symbol} {value} {datum} ‚Üí {tol_type}")
                else:
                    st.text(f"{symbol} {value} ‚Üí {tol_type}")
            with col2:
                st.checkbox("Correcte?", True, key=f"tol_{i}")
    else:
        st.info("No s'han detectat toler√†ncies geom√®triques en aquest document.")

with tab3:
    st.subheader("üìä Taules Extretes")
    
    if data.get("raw_tables"):
        for i, table in enumerate(data["raw_tables"]):
            with st.expander(f"Taula {i+1} - {table.get('type', 'Desconeguda')}"):
                if table.get("type") == "info_table":
                    st.json(table.get("data", {}))
                else:
                    table_data = table.get("data", [])
                    if isinstance(table_data, list) and table_data:
                        # Convertir a DataFrame si √©s possible
                        try:
                            df = pd.DataFrame(table_data)
                            st.dataframe(df, use_container_width=True)
                        except:
                            # Si no es pot convertir, mostrar com JSON
                            st.json(table_data)
                    else:
                        st.write("Taula buida o dades no v√†lides")
    else:
        st.info("No s'han extret taules d'aquest document.")

# Secci√≥ de finalitzaci√≥ i exportaci√≥
st.divider()
st.subheader("üíæ Finalitzaci√≥ i Exportaci√≥")

col1, col2 = st.columns(2)
with col1:
    if st.button("‚úÖ Finalitzar Validaci√≥", type="primary"):
        st.success("‚úÖ Validaci√≥ completada. Dades preparades per a exportar.")

with col2:
    st.write("**Opcions d'exportaci√≥:**")

# Secci√≥ d'exportaci√≥ millorada
st.subheader("üì§ Exportar Resultats")

# Crear les dades d'exportaci√≥ amb correccions de l'usuari
export_data = data.copy()

# Aplicar correccions de l'usuari
for i in range(len(data.get("dimensions", []))):
    if st.session_state.get(f'editing_dim_{i}', False):
        new_desc = st.session_state.get(f'new_desc_{i}', '')
        if new_desc and 'dimensions' in export_data:
            export_data["dimensions"][i]['description'] = new_desc
            export_data["dimensions"][i]['user_corrected'] = True

# Opcions d'exportaci√≥ en columnes
col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("**üìä Exportar a Excel**")
    st.write("Full de c√†lcul amb pestanyes separades per cada tipus de dada")
    
    try:
        excel_data = create_excel_export(export_data)
        st.download_button(
            label="‚¨áÔ∏è Descarregar Excel",
            data=excel_data,
            file_name=f"validacio_planols_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="excel_download"
        )
    except Exception as e:
        st.error(f"Error creant Excel: {e}")

with col2:
    st.markdown("**üìÑ JSON Schema Validat**")
    st.write("Fitxer JSON amb esquema de validaci√≥ incorporat")
    
    json_schema_data = create_json_schema_export(export_data)
    st.download_button(
        label="‚¨áÔ∏è Descarregar JSON Schema",
        data=json_schema_data,
        file_name=f"schema_validacio_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json",
        mime="application/json",
        key="json_schema_download"
    )

with col3:
    st.markdown("**üìã JSON Simple**")
    st.write("Format JSON est√†ndard per integraci√≥")
    
    # JSON simple amb metadades
    simple_json_data = {
        "validation_completed": True,
        "export_timestamp": str(pd.Timestamp.now().isoformat()),
        "data": export_data,
        "user_corrections": {
            "total_corrections": sum(1 for i in range(len(data.get("dimensions", []))) 
                                   if st.session_state.get(f'editing_dim_{i}', False))
        }
    }
    
    st.download_button(
        label="‚¨áÔ∏è Descarregar JSON",
        data=json.dumps(simple_json_data, indent=2, ensure_ascii=False),
        file_name=f"validacio_simple_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json",
        mime="application/json",
        key="json_simple_download"
    )

# Informaci√≥ addicional sobre exportaci√≥
with st.expander("‚ÑπÔ∏è Informaci√≥ sobre formats d'exportaci√≥"):
    st.markdown("""
    **üìä Format Excel (.xlsx):**
    - Cont√© pestanyes separades per: Informaci√≥ de Pe√ßa, Cotes, Toler√†ncies, Taules
    - Ideal per an√†lisi i edici√≥ manual
    - Compatible amb Microsoft Excel, LibreOffice Calc, Google Sheets
    
    **üìÑ JSON Schema:**
    - Inclou esquema de validaci√≥ JSON Schema v7
    - Estructura de dades validada autom√†ticament
    - Ideal per integraci√≥ amb sistemes externos
    
    **üìã JSON Simple:**
    - Format JSON est√†ndard sense esquema
    - Inclou metadades de validaci√≥ i correccions
    - Ideal per processament program√†tic simple
    """)
